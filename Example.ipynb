{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Note: This notebook was run on my local machine and the results are displayed here. The code cannot be run in Colab.",
   "id": "2c4f6cae7a26ec78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T19:18:40.311350Z",
     "start_time": "2024-08-30T19:18:39.853106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "from src.mcnnm.wrappers import estimate, complete_matrix\n",
    "from src.mcnnm.utils import generate_data"
   ],
   "id": "edc868e553979442",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example 1: Staggered Adoption with Cross-Validation (Default)\n",
    "In this example, we generate a dataset with covariates and staggered adoption treatment assignment and use the default cross-validation method for selecting the regularization parameters. Cross-validation is currently not parallelized and may take longer to run on large datasets or smaller processors."
   ],
   "id": "6e3bb5397c3bf295"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T19:20:32.339939Z",
     "start_time": "2024-08-30T19:20:28.693443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Y, W, X, Z, V, true_params = generate_data(\n",
    "        nobs=50,\n",
    "        nperiods=10,\n",
    "        unit_fe=True,\n",
    "        time_fe=True,\n",
    "        X_cov=True,\n",
    "        Z_cov=True,\n",
    "        V_cov=True,\n",
    "        seed=2024,\n",
    "        noise_scale=0.2,\n",
    "        autocorrelation=0.0,\n",
    "        assignment_mechanism=\"last_periods\",\n",
    "        treated_fraction=0.4,\n",
    "        last_treated_periods=3,\n",
    "    )\n",
    "\n",
    "# Run estimation\n",
    "results = estimate(\n",
    "    Y=Y,\n",
    "    W=W,\n",
    "    X=X,\n",
    "    Z=Z,\n",
    "    V=V,\n",
    "    Omega=None,\n",
    "    use_unit_fe=True,\n",
    "    use_time_fe=True,\n",
    "    lambda_L=None,\n",
    "    lambda_H=None,\n",
    "    validation_method='cv',  # type: ignore\n",
    "    K=10,  # Use 2 folds for faster testing\n",
    "    n_lambda=12,  # Use 3 lambda values for faster testing\n",
    "    max_iter=1e5,  # 12\n",
    "    tol=1e-5,  # 14\n",
    ")\n",
    "\n",
    "print(f\"\\nTrue effect: {true_params['treatment_effect']}, Estimated effect: {results.tau:.12f}\")\n",
    "print(f\"Chosen lambda_L: {results.lambda_L:.4f}, lambda_H: {results.lambda_H:.4f}\")"
   ],
   "id": "f9d5f734290a1949",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True effect: 5.0, Estimated effect: 5.272798700257\n",
      "Chosen lambda_L: 0.0000, lambda_H: 0.1806\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The `generate_data` function is used to create a synthetic dataset with staggered adoption treatment assignment. The assignment_mechanism parameter is set to `staggered`, which means that each unit adopts the treatment at a random time point with a specified probability.\n",
    "By default, the estimate function uses cross-validation to select the optimal regularization parameters lambda_L and lambda_H. Cross-validation splits the data into K folds (default is 5) and evaluates the model performance on each fold to select the best parameters."
   ],
   "id": "80d9bed6f21c790e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example 2: Block Assignment with Holdout Validation\n",
    "In this example, we generate a dataset without covariates using block treatment assignment and use holdout validation for selecting the regularization parameters."
   ],
   "id": "526c2a08eb8622f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T14:24:17.706848Z",
     "start_time": "2024-08-30T14:24:17.413082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "results = estimate(Y, W, validation_method='holdout')\n",
    "\n",
    "print(f\"\\nTrue effect: {true_params['treatment_effect']}, Estimated effect: {results.tau:.4f}\")\n",
    "print(f\"Chosen lambda_L: {results.lambda_L:.4f}, lambda_H: {results.lambda_H:.4f}\")"
   ],
   "id": "9e8f385b8b8aa18d",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Holdout validation requires initial_window, step_size, and horizon.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mestimate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mW\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mholdout\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mTrue effect: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrue_params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtreatment_effect\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Estimated effect: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresults\u001B[38;5;241m.\u001B[39mtau\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChosen lambda_L: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresults\u001B[38;5;241m.\u001B[39mlambda_L\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, lambda_H: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresults\u001B[38;5;241m.\u001B[39mlambda_H\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Git/mcnnm/src/mcnnm/wrappers.py:295\u001B[0m, in \u001B[0;36mestimate\u001B[0;34m(Y, W, X, Z, V, Omega, use_unit_fe, use_time_fe, lambda_L, lambda_H, n_lambda, max_iter, tol, validation_method, K, initial_window, step_size, horizon, max_window_size)\u001B[0m\n\u001B[1;32m    293\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m validation_method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mholdout\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    294\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m initial_window \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m step_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m horizon \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# pragma: no cover\u001B[39;00m\n\u001B[0;32m--> 295\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(  \u001B[38;5;66;03m# pragma: no cover\u001B[39;00m\n\u001B[1;32m    296\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHoldout validation requires initial_window, step_size, and horizon.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    297\u001B[0m         )\n\u001B[1;32m    299\u001B[0m     initial_window, step_size, horizon, K, max_window_size \u001B[38;5;241m=\u001B[39m validate_holdout_config(\n\u001B[1;32m    300\u001B[0m         initial_window,  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    301\u001B[0m         step_size,  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    305\u001B[0m         T,\n\u001B[1;32m    306\u001B[0m     )\n\u001B[1;32m    307\u001B[0m     opt_lambda_L, opt_lambda_H, lambda_L_opt_range, lambda_H_opt_range \u001B[38;5;241m=\u001B[39m holdout_validate(\n\u001B[1;32m    308\u001B[0m         Y\u001B[38;5;241m=\u001B[39mY,\n\u001B[1;32m    309\u001B[0m         X\u001B[38;5;241m=\u001B[39mX,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    323\u001B[0m         tol\u001B[38;5;241m=\u001B[39mtol,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    324\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Holdout validation requires initial_window, step_size, and horizon."
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here, the `assignment_mechanism` is set to `block`, which means that a specified fraction of units (determined by `treated_fraction`) are treated in the second half of the time periods.\n",
    "The validation_method parameter in the estimate function is set to `holdout`, indicating that holdout validation should be used for selecting the regularization parameters. Holdout validation splits the data into a training set and a validation set based on time. It uses the earlier time periods for training and the later time periods for validation. Holdout validation is typically faster than cross-validation but may be less accurate, especially if the number of time periods is small."
   ],
   "id": "73b77c2807eb8996"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example 3: Single Treated Unit with Covariates\n",
    "In this example, we generate a dataset with a single treated unit and include covariates in the estimation."
   ],
   "id": "c32515a2c437e228"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data, true_params = generate_data(nobs=100, nperiods=200, seed=456, assignment_mechanism='single_treated_unit', \n",
    "                                  X_cov=True, Z_cov=True, V_cov=True)\n",
    "\n",
    "Y = jnp.array(data.pivot(index='unit', columns='period', values='y').values)\n",
    "W = jnp.array(data.pivot(index='unit', columns='period', values='treat').values)\n",
    "X = jnp.array(true_params['X'])\n",
    "Z = jnp.array(true_params['Z'])\n",
    "V = jnp.array(true_params['V'])\n",
    "\n",
    "results = estimate(Y, W, X=X, Z=Z, V=V, K=3)\n",
    "\n",
    "print(f\"\\nTrue effect: {true_params['treatment_effect']}, Estimated effect: {results.tau:.4f}\")\n",
    "print(f\"Chosen lambda_L: {results.lambda_L:.4f}, lambda_H: {results.lambda_H:.4f}\")"
   ],
   "id": "6ebcbab8622b2f78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The `assignment_mechanism` is set to `'single_treated_unit'`, which means that only one randomly selected unit is treated in the second half of the time periods.\n",
    "\n",
    "In this example, we include unit-specific covariates `X`, time-specific covariates `Z`, and unit-time specific covariates `V` in the estimation. The `estimate` function automatically handles the presence of covariates and estimates their coefficients along with the treatment effect.\n",
    "\n",
    "With this specific dataset, the estimated treatment effect is not close to the true treatment effect, as the single treated unit leads to the cross-validation method struggling to find a valid loss during the parameter selection process. The warning message \"No valid loss found in cross_validate\" indicates that the cross-validation procedure could not find a suitable set of regularization parameters that yielded a finite loss value.\n",
    "\n",
    "This issue arises because with only a single treated unit, there might not be enough information to reliably estimate the treatment effect, especially when using cross-validation. The limited treatment variation can make it challenging for the model to distinguish the treatment effect from the noise in the data.\n",
    "\n",
    "In such cases, it may be more appropriate to use a different validation method, such as holdout validation, or to rely on domain knowledge to set the regularization parameters manually. Additionally, increasing the number of observations or treated units can help improve the estimation accuracy and stability.\n",
    "\n",
    "It's important to note that the performance of the estimation method can be sensitive to the specific dataset and the chosen assignment mechanism. While the `estimate` function aims to handle various scenarios, there may be limitations in extreme cases like having only a single treated unit. It's always a good practice to carefully evaluate the results, consider the characteristics of the dataset, and interpret the findings in the context of the specific application."
   ],
   "id": "1c6b3bb9e0f55db4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example 4: Custom Lambda Grid with Cross-Validation\n",
    "\n",
    "In this example, we demonstrate how to use  custom lambda values for cross-validation. As the `n_lambda_L` and `n_lambda_H` parameters are set to 3, the cross-validation method will select the best lambda values from around the specified values."
   ],
   "id": "28885de282b55b85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data, true_params = generate_data(nobs=100, nperiods=50, seed=789, assignment_mechanism='staggered')\n",
    "\n",
    "Y = jnp.array(data.pivot(index='unit', columns='period', values='y').values)\n",
    "W = jnp.array(data.pivot(index='unit', columns='period', values='treat').values)\n",
    "\n",
    "results = estimate(Y, W, lambda_L=0.1, n_lambda_L=3, lambda_H=0.01, n_lambda_H=3)\n",
    "\n",
    "print(f\"\\nTrue effect: {true_params['treatment_effect']}, Estimated effect: {results.tau:.4f}\")\n",
    "print(f\"Chosen lambda_L: {results.lambda_L:.4f}, lambda_H: {results.lambda_H:.4f}\")"
   ],
   "id": "533adeedc78a9650",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example 5: Estimation with Holdout Validation\n",
    "In this example, we generate data with staggered adoption treatment assignment and use holdout validation for selecting the regularization parameters. The `max_window_size` parameter is set to 80, which controls the maximum size of the training window in the holdout validation process."
   ],
   "id": "e97ba235c96b2d2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data, true_params = generate_data(nobs=200, nperiods=100, seed=101, assignment_mechanism='staggered')\n",
    "\n",
    "Y = jnp.array(data.pivot(index='unit', columns='period', values='y').values)\n",
    "W = jnp.array(data.pivot(index='unit', columns='period', values='treat').values)\n",
    "\n",
    "results = estimate(Y, W, validation_method='holdout', max_window_size=80)\n",
    "\n",
    "print(f\"\\nTrue effect: {true_params['treatment_effect']}, Estimated effect: {results.tau:.4f}\")\n",
    "print(f\"Chosen lambda_L: {results.lambda_L:.4f}, lambda_H: {results.lambda_H:.4f}\")"
   ],
   "id": "1e43672a3205965b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example 6: Estimation with Pre-specified Lambda Values\n",
    "\n",
    "This example shows how to estimate the model using pre-specified lambda values."
   ],
   "id": "398a39f7c3c6d189"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data, true_params = generate_data(nobs=150, nperiods=75, seed=202, assignment_mechanism='staggered')\n",
    "\n",
    "Y = jnp.array(data.pivot(index='unit', columns='period', values='y').values)\n",
    "W = jnp.array(data.pivot(index='unit', columns='period', values='treat').values)\n",
    "\n",
    "results = estimate(Y, W, lambda_L=0.05, lambda_H=0.01)\n",
    "\n",
    "print(f\"\\nTrue effect: {true_params['treatment_effect']}, Estimated effect: {results.tau:.4f}\")\n",
    "print(f\"Used lambda_L: {results.lambda_L:.4f}, lambda_H: {results.lambda_H:.4f}\")"
   ],
   "id": "19d4b2103db91295",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example 7: Estimation with Autocorrelation\n",
    "\n",
    "In this example, we generate data with autocorrelation (see section 8.3 of [Athey et al. (2021)](https://www.tandfonline.com/doi/full/10.1080/01621459.2021.1891924)) and use a custom Omega matrix in estimation."
   ],
   "id": "bba79241d63d5888"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data, true_params = generate_data(nobs=120, nperiods=60, seed=303, assignment_mechanism='staggered', autocorrelation=0.5)\n",
    "\n",
    "Y = jnp.array(data.pivot(index='unit', columns='period', values='y').values)\n",
    "W = jnp.array(data.pivot(index='unit', columns='period', values='treat').values)\n",
    "\n",
    "# Create custom Omega matrix with AR(1) structure\n",
    "rho = 0.5\n",
    "T = Y.shape[1]\n",
    "Omega = jnp.power(rho, jnp.abs(jnp.arange(T)[:, None] - jnp.arange(T)))\n",
    "\n",
    "results = estimate(Y, W, Omega=Omega)\n",
    "\n",
    "print(f\"\\nTrue effect: {true_params['treatment_effect']}, Estimated effect: {results.tau:.4f}\")\n",
    "print(f\"Chosen lambda_L: {results.lambda_L:.4f}, lambda_H: {results.lambda_H:.4f}\")"
   ],
   "id": "87cd3deef5f42db1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example 8: Matrix Completion\n",
    "\n",
    "This example demonstrates how to use the `complete_matrix()` function to impute missing values."
   ],
   "id": "749eb646eed6c068"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data, true_params = generate_data(nobs=200, nperiods=40, seed=404, treatment_probability=0.2)\n",
    "\n",
    "Y = jnp.array(data.pivot(index='unit', columns='period', values='y').values)\n",
    "W = jnp.array(data.pivot(index='unit', columns='period', values='treat').values)  # randomly mask out entries\n",
    "\n",
    "results = complete_matrix(Y, W)\n",
    "\n",
    "print(f\"Chosen lambda_L: {results.lambda_L:.4f}, lambda_H: {results.lambda_H:.4f}\")\n",
    "print(f\"Mean absolute error of imputation: {jnp.mean(jnp.abs(Y - results.Y_completed)):.4f}\")"
   ],
   "id": "c3e5d22b85e3c59a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example 9: Different Treatment Assignment Mechanisms\n",
    "\n",
    "This example showcases the 'single_treated_period' and 'last_periods' assignment mechanisms."
   ],
   "id": "e7efc83eb0bfaf75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Single treated period\n",
    "data_single, true_params_single = generate_data(nobs=200, nperiods=100, seed=505, \n",
    "                                                assignment_mechanism='single_treated_period')\n",
    "\n",
    "Y_single = jnp.array(data_single.pivot(index='unit', columns='period', values='y').values)\n",
    "W_single = jnp.array(data_single.pivot(index='unit', columns='period', values='treat').values)\n",
    "\n",
    "results_single = estimate(Y_single, W_single)\n",
    "\n",
    "print(\"Single Treated Period:\")\n",
    "print(f\"True effect: {true_params_single['treatment_effect']}, Estimated effect: {results_single.tau:.4f}\")\n",
    "\n",
    "# Last periods treated\n",
    "data_last, true_params_last = generate_data(nobs=200, nperiods=100, seed=606, \n",
    "                                            assignment_mechanism='last_periods', last_treated_periods=20)\n",
    "\n",
    "Y_last = jnp.array(data_last.pivot(index='unit', columns='period', values='y').values)\n",
    "W_last = jnp.array(data_last.pivot(index='unit', columns='period', values='treat').values)\n",
    "\n",
    "results_last = estimate(Y_last, W_last)\n",
    "\n",
    "print(\"\\nLast Periods Treated:\")\n",
    "print(f\"True effect: {true_params_last['treatment_effect']}, Estimated effect: {results_last.tau:.4f}\")"
   ],
   "id": "9038c5a4246d8135",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Covariates\n",
    "The `generate_data` function allows you to include three types of covariates in the generated dataset:\n",
    "\n",
    "1. **Unit-specific covariates (X):** These are characteristics or features that vary across units but remain constant over time. For example, in a study of students' academic performance, unit-specific covariates could include variables like gender, age, or socioeconomic status. These covariates capture the inherent differences between units that may influence the outcome variable.\n",
    "2. **Time-specific covariates (Z):** These are factors that change over time but are the same for all units at each time point. For instance, in an analysis of sales data, time-specific covariates could include variables like market trends, seasonal effects, or economic indicators. These covariates reflect the temporal variations that affect all units simultaneously.\n",
    "3. **Unit-time specific covariates (V):** These are covariates that vary both across units and over time. They capture the unique characteristics of each unit at each time point. For example, in a healthcare study, unit-time specific covariates could include individual patients' medical measurements or treatment adherence recorded at different time points. These covariates allow for capturing the dynamic and personalized aspects of each unit's experience.\n",
    "\n",
    "These three options are available for estimation, mirroring the description of the estimator in [Athey et al. (2021)](https://www.tandfonline.com/doi/full/10.1080/01621459.2021.1891924).\n",
    "\n",
    "In the `generate_data` function, you can control the inclusion of these covariates using the boolean flags X_cov, Z_cov, and V_cov. Setting these flags to True incorporates the respective type of covariates into the generated dataset, while setting them to False excludes them."
   ],
   "id": "7d5694fda39da545"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
